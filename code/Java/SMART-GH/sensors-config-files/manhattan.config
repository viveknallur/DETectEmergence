[ConnectionSettings]
REDIS_URL= localhost
HASH = sensor_data
CITY_PREFIX =  dublin

[SensorsAvailable]
#sensor1 = Noisetube
sensor2 = DublinCityCouncilAirPollution

[Noisetube]
# The text that will appear in the web app page indicating the weighing options. The user can choose between fastest, shortest (which are supported by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Noisy 

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = noise

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_nt_webservice


# URL where the webservice that retrieves data from sensors is located
url = http://www.noisetube.net/api/search.json?key=

# API key of the user calling the webservice
api_key = 12da65cd7932fb3a0543009fb78ba08711bed72b

# ID of the city we want to retrieve data about. Currently, this is obtained by 
# sending a polite email to the NoiseTube admin
city_id = 136

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_noise_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.exponential_weighted_moving_average

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/noise/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = latest_noisetube_readings.json

# The number of metres where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[DublinCityCouncilAirPollution]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Air_Pollution

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = air

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice


# URL where the webservice that retrieves data from sensors is located
url = http://www.noisetube.net/api/search.json?key=

# API key of the user calling the webservice
api_key = 12da65cd7932fb3a0543009fb78ba08711bed72b

# ID of the city we want to retrieve data about. Currently, this is obtained by 
# sending a polite email to the NoiseTube admin
city_id = 136

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_air_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/air/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.csv

# The number of metres where the sensor's readings propagate to
propagation = 500

# The number of days that aggregation filter will take into consideration
days = 3





